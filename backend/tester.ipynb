{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68838b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = [\n",
    "    r'''Matias Cattaneo\n",
    "Position\n",
    "Professor\n",
    "Website\n",
    "Matias Cattaneo's Site\n",
    "Office Phone\n",
    "(609) 258-8825\n",
    "Email\n",
    "cattaneo@princeton.edu\n",
    "Office\n",
    "230 - Sherrerd Hall\n",
    "Bio/Description\n",
    "Research Interests: Econometrics, statistics, machine learning, data science, causal inference, program evaluation, quantitative methods in the social, behavioral and biomedical sciences.''',\n",
    "    r'''Jianqing Fan\n",
    "Position\n",
    "Frederick L. Moore Professor in Finance\n",
    "Website\n",
    "Jianqing Fan's Site\n",
    "Office Phone\n",
    "(609) 258-7924\n",
    "Email\n",
    "jqfan@princeton.edu\n",
    "Office\n",
    "205 - Sherrerd Hall\n",
    "Bio/Description\n",
    "Research Interests: High-dimensional statistics, Machine Learning, financial econometrics, computational biology, biostatistics, graphical and network modeling, portfolio theory, high-frequency finance, time series.''',\n",
    "    r'''Jason Klusowski\n",
    "Position\n",
    "Assistant Professor\n",
    "Website\n",
    "Jason Klusowski's Site\n",
    "Office Phone\n",
    "(609) 258-5305\n",
    "Email\n",
    "jason.klusowski@princeton.edu\n",
    "Office\n",
    "327 - Sherrerd Hall\n",
    "Bio/Description\n",
    "Research Interests: Data science, statistical learning, deep learning, decision tree learning; high-dimensional statistics, information theory, statistical physics, network modeling'''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a772eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "novita_client = OpenAI(\n",
    "    api_key=os.getenv(\"novita_api_key\"),\n",
    "    base_url=\"https://api.novita.ai/openai\"\n",
    ")\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.getenv(\"openai_api_key\")\n",
    ")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=os.getenv(\"claude_api_key\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9851ed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm always happy to chat and help with any questions or topics you'd like to discuss. How about you? How's your day going so far?\n",
      "CompletionUsage(completion_tokens=63, prompt_tokens=47, total_tokens=110, completion_tokens_details=None, prompt_tokens_details=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"novita_api_key\"),\n",
    "    base_url=\"https://api.novita.ai/openai\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "    ],\n",
    "    max_tokens=120000,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de16804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task prompt created and formatted with profiles\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the task prompt for analyzing professor profiles\n",
    "task_prompt = \"\"\"\n",
    "You are an expert academic researcher. Please analyze the following professor profiles and provide:\n",
    "\n",
    "1. A summary of each professor's research focus\n",
    "2. Potential collaboration opportunities between them\n",
    "3. Emerging research trends in their fields\n",
    "4. Recommendations for interdisciplinary research projects\n",
    "\n",
    "Here are the professor profiles:\n",
    "\n",
    "{profiles}\n",
    "\n",
    "Please provide a comprehensive analysis that would be valuable for academic planning and research strategy.\n",
    "\"\"\"\n",
    "\n",
    "# Format the prompt with the actual profiles\n",
    "formatted_prompt = task_prompt.format(profiles=\"\\n\\n\".join(profiles))\n",
    "print(\"Task prompt created and formatted with profiles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5af9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with OpenAI GPT-4...\n",
      "OpenAI Response:\n",
      "==================================================\n",
      "1. Summary of each professor's research focus:\n",
      "\n",
      "- Professor Matias Cattaneo's primary research interests revolve around econometrics, statistics, machine learning, data science, causal inference, program evaluation, and quantitative methods in the social, behavioral, and biomedical sciences. His research appears to be quite interdisciplinary, with a strong focus on the application of quantitative methods and data analysis across various sectors.\n",
      "\n",
      "- Professor Jianqing Fan specializes in high-dimensional statistics, machine learning, financial econometrics, computational biology, biostatistics, graphical and network modeling, portfolio theory, high-frequency finance, and time series. His research incorporates a blend of statistical and computational approaches to financial and biological problems.\n",
      "\n",
      "- Assistant Professor Jason Klusowski's research areas include data science, statistical learning, deep learning, decision tree learning, high-dimensional statistics, information theory, statistical physics, and network modeling. He is particularly interested in the theoretical aspects of data science and machine learning, with a focus on high-dimensional statistics and network modeling.\n",
      "\n",
      "2. Potential collaboration opportunities between them:\n",
      "\n",
      "Given their shared interests in machine learning, high-dimensional statistics, and data science, there are ample opportunities for collaboration. For example, they could collectively work on projects that apply machine learning techniques to social, behavioral, and biomedical data. They could also explore the application of high-dimensional statistics and network modeling in financial econometrics and portfolio theory. \n",
      "\n",
      "3. Emerging research trends in their fields:\n",
      "\n",
      "In the field of machine learning and data science, one of the emerging trends is the use of deep learning in handling complex, high-dimensional data. In econometrics and finance, the focus is increasingly shifting towards high-frequency finance and the use of advanced statistical techniques to model financial markets. In biomedical sciences, computational biology and biostatistics are emerging as crucial tools for understanding biological systems and diseases.\n",
      "\n",
      "4. Recommendations for interdisciplinary research projects:\n",
      "\n",
      "- An interdisciplinary project could involve the application of machine learning and high-dimensional statistics to understand the dynamics of financial markets. This could combine Professor Fan's expertise in financial econometrics with Professor Cattaneo's and Professor Klusowski's knowledge of machine learning and high-dimensional statistics.\n",
      "\n",
      "- Another project could involve the use of advanced statistical methods to analyze social and behavioral science data. This could leverage Professor Cattaneo's expertise in econometrics and quantitative methods in social sciences, along with Professor Klusowski's and Professor Fan's skills in machine learning and statistics.\n",
      "\n",
      "- A third project could focus on applying machine learning and statistical learning techniques to computational biology and biostatistics, combining the expertise of all three professors.\n",
      "==================================================\n",
      "Token usage: CompletionUsage(completion_tokens=518, prompt_tokens=356, total_tokens=874, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Test the prompt with OpenAI\n",
    "print(\"Testing with OpenAI GPT-4...\")\n",
    "\n",
    "openai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "openai_output = openai_response.choices[0].message.content\n",
    "openai_usage = openai_response.usage\n",
    "\n",
    "print(\"OpenAI Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(openai_output)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Token usage: {openai_usage}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9280c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Llama 3.3 70B via Novita...\n",
      "Llama Response:\n",
      "==================================================\n",
      "### 1. Summary of Each Professor's Research Focus\n",
      "\n",
      "- **Matias Cattaneo**: Professor Cattaneo's research interests are broadly centered around quantitative methods, with a focus on econometrics, statistics, machine learning, data science, causal inference, and program evaluation. His work spans across the social, behavioral, and biomedical sciences, indicating a wide applicability of his research methodologies.\n",
      "\n",
      "- **Jianqing Fan**: Professor Fan's research is concentrated in the areas of high-dimensional statistics, machine learning, financial econometrics, and biostatistics. He also explores graphical and network modeling, portfolio theory, high-frequency finance, and time series analysis. This diversity suggests a strong foundation in statistical analysis with applications in finance and biology.\n",
      "\n",
      "- **Jason Klusowski**: Professor Klusowski's research focus includes data science, statistical learning, deep learning, decision tree learning, and high-dimensional statistics. Additionally, his interests in information theory, statistical physics, and network modeling indicate a blend of theoretical and applied research, potentially bridging computer science, physics, and statistics.\n",
      "\n",
      "### 2. Potential Collaboration Opportunities\n",
      "\n",
      "Given their research interests, there are several potential collaboration opportunities among these professors:\n",
      "\n",
      "- **Integration of Machine Learning and Econometrics**: Professors Cattaneo and Fan could collaborate on projects that apply machine learning techniques to econometric problems, such as forecasting economic trends or analyzing the impact of policy interventions.\n",
      "  \n",
      "- **High-Dimensional Data Analysis in Finance and Biomedicine**: Professors Fan and Klusowski might work together on analyzing high-dimensional data in finance (e.g., portfolio optimization) and biomedicine (e.g., genomic analysis), leveraging their expertise in statistical learning and network modeling.\n",
      "  \n",
      "- **Causal Inference and Decision Making**: Professors Cattaneo and Klusowski could explore how causal inference methods, combined with decision tree learning and deep learning, can inform decision-making processes in social sciences, healthcare, and finance.\n",
      "  \n",
      "- **Interdisciplinary Research in Network Science**: All three professors could collaborate on projects involving network modeling, applying their collective expertise to study complex networks in finance, biology, and social sciences, potentially uncovering new insights into systemic risks, disease spread, or social influence.\n",
      "\n",
      "### 3. Emerging Research Trends in Their Fields\n",
      "\n",
      "- **Increased Use of Machine Learning and AI**: There's a growing trend towards leveraging machine learning and artificial intelligence in econometrics, finance, and biostatistics for predictive modeling, risk analysis, and personalized interventions.\n",
      "  \n",
      "- **Big Data and High-Dimensional Statistics**: The explosion of big data necessitates advanced statistical techniques for analysis, particularly in high-dimensional settings, which is a common thread among the research interests of these professors.\n",
      "  \n",
      "- **Network Science and Complex Systems**: Studying networks and complex systems is becoming increasingly important across disciplines, from understanding financial systems' stability to modeling disease spread in populations.\n",
      "  \n",
      "- **Causal Inference and Explainability**: As machine learning models become more prevalent, there's a rising interest in causal inference to understand the underlying mechanisms of these models and in explainability to make their predictions more transparent and trustworthy.\n",
      "\n",
      "### 4. Recommendations for Interdisciplinary Research Projects\n",
      "\n",
      "1. **Financial Network Stability and Systemic Risk**: This project could combine network modeling, high-dimensional statistics, and machine learning to analyze and predict systemic risks in financial networks.\n",
      "   \n",
      "2. **Personalized Medicine through Machine Learning**: By integrating biostatistics, machine learning, and causal inference, researchers could develop personalized treatment strategies based on individual patient characteristics and genetic profiles.\n",
      "   \n",
      "3. **Social Network Analysis for Public Health Interventions**: This project would apply network science, statistical learning, and causal inference to understand how social networks influence the spread of diseases and the effectiveness of public health interventions.\n",
      "   \n",
      "4. **Econophysics and Complex Economic Systems**: Researchers could use methods from statistical physics and network science to model and analyze complex economic systems, potentially revealing new insights into economic stability and the impact of policy interventions.\n",
      "\n",
      "These projects would not only leverage the strengths of each professor but also contribute to advancing knowledge in their respective fields and fostering interdisciplinary collaboration.\n",
      "==================================================\n",
      "Token usage: CompletionUsage(completion_tokens=835, prompt_tokens=382, total_tokens=1217, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Test the same prompt with Llama via Novita\n",
    "print(\"Testing with Llama 3.3 70B via Novita...\")\n",
    "\n",
    "llama_response = novita_client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "llama_output = llama_response.choices[0].message.content\n",
    "llama_usage = llama_response.usage\n",
    "\n",
    "print(\"Llama Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(llama_output)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Token usage: {llama_usage}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b874465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing outputs and generating improved prompt...\n",
      "Analysis:\n",
      "==================================================\n",
      "1. Key Differences in Quality, Depth, and Structure:\n",
      "\n",
      "- Quality: Both responses are of high quality, providing a comprehensive analysis of the professors' research interests, potential collaborations, emerging trends, and interdisciplinary project recommendations. However, the GPT-4 response appears to be slightly more concise and direct, while the Llama response provides more detailed explanations and examples.\n",
      "\n",
      "- Depth: The Llama response delves deeper into the professors' research interests, providing more context and potential applications of their work. It also offers more specific examples of potential collaborations and interdisciplinary projects. The GPT-4 response, while thorough, is somewhat more general in its suggestions.\n",
      "\n",
      "- Structure: Both responses follow a similar structure, addressing each point in the original prompt in order. However, the Llama response uses bold headings for each section, making it easier to navigate and understand. The GPT-4 response, while well-organized, does not use such clear visual cues.\n",
      "\n",
      "2. Aspects of the Llama Response That Could Be Improved:\n",
      "\n",
      "- Specificity: While the Llama response is generally quite specific, it could further improve by providing more concrete examples or case studies that relate to the professors' research interests. For instance, it could mention specific projects or papers that the professors have worked on.\n",
      "\n",
      "- Brevity: The Llama response is quite lengthy and detailed, which can be a strength but also a potential weakness. Some sections could be condensed for clarity and brevity, making the response more digestible.\n",
      "\n",
      "- Personalization: The Llama response could benefit from more personalized recommendations for each professor, taking into account their individual strengths and interests. For example, it could suggest specific roles each professor could play in the proposed interdisciplinary projects.\n",
      "\n",
      "To improve the prompt for the Llama model, it could be beneficial to ask for specific examples or case studies related to the professors' research interests. The prompt could also request more personalized recommendations for each professor and encourage a balance between detail and brevity. For example:\n",
      "\n",
      "\"Please provide a comprehensive analysis of the professors' research interests, potential collaborations, and emerging trends in their fields. Include specific examples or case studies that relate to their research. Suggest interdisciplinary projects that take into account each professor's individual strengths and interests. Aim for a balance between detail and brevity, ensuring your response is both thorough and easy to understand.\"\n",
      "==================================================\n",
      "Token usage: CompletionUsage(completion_tokens=476, prompt_tokens=1823, total_tokens=2299, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "\n",
      "Improved Prompt:\n",
      "==================================================\n",
      "\"Please provide a comprehensive analysis of the professors' research interests, potential collaborations, and emerging trends in their fields. Include specific examples or case studies that relate to their research. Suggest interdisciplinary projects that take into account each professor's individual strengths and interests. Aim for a balance between detail and brevity, ensuring your response is both thorough and easy to understand.\"\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Feed both outputs to GPT for comparison and prompt improvement\n",
    "print(\"Analyzing outputs and generating improved prompt...\")\n",
    "\n",
    "comparison_prompt = f\"\"\"\n",
    "You are an expert in prompt engineering and AI model optimization. I have two responses to the same prompt from different AI models:\n",
    "\n",
    "ORIGINAL PROMPT:\n",
    "{formatted_prompt}\n",
    "\n",
    "OPENAI GPT-4 RESPONSE:\n",
    "{openai_output}\n",
    "\n",
    "LLAMA 3.3 70B RESPONSE:\n",
    "{llama_output}\n",
    "\n",
    "Please analyze these responses and:\n",
    "\n",
    "1. Identify the key differences in quality, depth, and structure between the two responses\n",
    "2. Determine what specific aspects of the Llama response could be improved\n",
    "\n",
    "Focus on making the prompt more specific, providing better structure guidance, and addressing any weaknesses you observe in the Llama response.\n",
    "\"\"\"\n",
    "\n",
    "comparison_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": comparison_prompt}\n",
    "    ],\n",
    "    max_tokens=3000,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "comparison_output = comparison_response.choices[0].message.content\n",
    "comparison_usage = comparison_response.usage\n",
    "\n",
    "print(\"Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(comparison_output)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Token usage: {comparison_usage}\")\n",
    "print()\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": comparison_prompt}, {\"role\": \"assistant\", \"content\": comparison_output}, {'role': 'user', 'content': 'Please provide the improved prompt only.'}]\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.3\n",
    ")\n",
    "print(\"Improved Prompt:\")\n",
    "print(\"=\" * 50)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec5aa3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing improved prompt with Llama...\n",
      "Improved Llama Response:\n",
      "==================================================\n",
      "After conducting an in-depth analysis of the professors' research interests, potential collaborations, and emerging trends in their fields, I have identified several areas of synergy and opportunities for interdisciplinary projects. Below, I provide a comprehensive overview of the professors' research interests, potential collaborations, and emerging trends, along with specific examples and case studies.\n",
      "\n",
      "**Professor 1: Environmental Science**\n",
      "\n",
      "* Research interests: Climate change, sustainable development, and environmental policy\n",
      "* Potential collaborations: Professors with expertise in economics, politics, and sociology\n",
      "* Emerging trends: Climate resilience, green infrastructure, and environmental justice\n",
      "* Example: A case study on the impact of climate change on coastal communities, highlighting the need for interdisciplinary approaches to address environmental and social challenges.\n",
      "\n",
      "**Professor 2: Artificial Intelligence**\n",
      "\n",
      "* Research interests: Machine learning, natural language processing, and computer vision\n",
      "* Potential collaborations: Professors with expertise in data science, cognitive psychology, and philosophy\n",
      "* Emerging trends: Explainable AI, human-AI collaboration, and AI ethics\n",
      "* Example: A project on developing AI-powered chatbots for mental health support, requiring collaboration with experts in psychology and human-computer interaction.\n",
      "\n",
      "**Professor 3: Public Health**\n",
      "\n",
      "* Research interests: Global health, health disparities, and health policy\n",
      "* Potential collaborations: Professors with expertise in epidemiology, sociology, and economics\n",
      "* Emerging trends: Precision medicine, global health security, and health systems strengthening\n",
      "* Example: A study on the impact of socioeconomic factors on health outcomes in low-income communities, highlighting the need for interdisciplinary approaches to address health disparities.\n",
      "\n",
      "**Interdisciplinary Project Ideas:**\n",
      "\n",
      "1. **Climate Change and Human Health**: Collaborate with Professors 1 and 3 to investigate the impact of climate change on human health, developing strategies for climate-resilient healthcare systems.\n",
      "2. **AI-powered Environmental Monitoring**: Combine the expertise of Professors 1 and 2 to develop AI-powered systems for environmental monitoring, predicting, and mitigating the effects of climate change.\n",
      "3. **Healthcare Access and AI**: Partner with Professors 2 and 3 to develop AI-powered solutions for improving healthcare access and outcomes in underserved communities, addressing health disparities and social determinants of health.\n",
      "4. **Sustainable Development and Policy**: Collaborate with Professors 1 and 3 to analyze the impact of policy interventions on sustainable development, using data science and machine learning techniques to inform evidence-based decision-making.\n",
      "\n",
      "**Emerging Trends and Future Directions:**\n",
      "\n",
      "1. **Interdisciplinary approaches to address complex challenges**: Encourage collaboration across departments and disciplines to tackle complex problems, such as climate change, health disparities, and AI ethics.\n",
      "2. **Data-driven decision-making**: Leverage data science and machine learning techniques to inform policy and decision-making, ensuring evidence-based approaches to address societal challenges.\n",
      "3. **Global perspectives and collaborations**: Foster international collaborations and incorporate global perspectives to address pressing issues, such as global health security, climate change, and sustainable development.\n",
      "\n",
      "By leveraging the strengths and interests of each professor, these interdisciplinary projects can drive innovative research, foster collaboration, and address complex challenges, ultimately contributing to a better understanding of the world and improving human well-being.\n",
      "==================================================\n",
      "Token usage: CompletionUsage(completion_tokens=649, prompt_tokens=107, total_tokens=756, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Extract and test the improved prompt\n",
    "\n",
    "improved_prompt_match = response.choices[0].message.content\n",
    "improved_prompt = improved_prompt_match.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "# Test the improved prompt with Llama\n",
    "print(\"\\nTesting improved prompt with Llama...\")\n",
    "\n",
    "improved_llama_response = novita_client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": improved_prompt}\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "improved_llama_output = improved_llama_response.choices[0].message.content\n",
    "improved_llama_usage = improved_llama_response.usage\n",
    "\n",
    "print(\"Improved Llama Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(improved_llama_output)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Token usage: {improved_llama_usage}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236c473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT OPTIMIZATION TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "1. ORIGINAL PROMPT:\n",
      "------------------------------\n",
      "\n",
      "You are an expert academic researcher. Please analyze the following professor profiles and provide:\n",
      "\n",
      "1. A summary of each professor's research focus\n",
      "2. Potential collaboration opportunities between t...\n",
      "\n",
      "2. OPENAI GPT-4 OUTPUT LENGTH: 3118 characters\n",
      "   Token usage: CompletionUsage(completion_tokens=518, prompt_tokens=356, total_tokens=874, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "\n",
      "3. LLAMA 3.3 70B OUTPUT LENGTH: 4859 characters\n",
      "   Token usage: CompletionUsage(completion_tokens=835, prompt_tokens=382, total_tokens=1217, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "\n",
      "4. ANALYSIS AND IMPROVED PROMPT LENGTH: 2642 characters\n",
      "   Token usage: CompletionUsage(completion_tokens=476, prompt_tokens=1823, total_tokens=2299, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "\n",
      "5. IMPROVED LLAMA OUTPUT LENGTH: 3745 characters\n",
      "   Token usage: CompletionUsage(completion_tokens=649, prompt_tokens=107, total_tokens=756, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "\n",
      "6. COMPARISON:\n",
      "------------------------------\n",
      "Original Llama vs Improved Llama:\n",
      "  Original: 4859 chars, 1217 tokens\n",
      "  Improved: 3745 chars, 756 tokens\n",
      "\n",
      "Test completed! Check the outputs above to evaluate the effectiveness of the prompt optimization.\n"
     ]
    }
   ],
   "source": [
    "# Summary and Results\n",
    "print(\"PROMPT OPTIMIZATION TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. ORIGINAL PROMPT:\")\n",
    "print(\"-\" * 30)\n",
    "print(formatted_prompt[:200] + \"...\" if len(formatted_prompt) > 200 else formatted_prompt)\n",
    "\n",
    "print(f\"\\n2. OPENAI GPT-4 OUTPUT LENGTH: {len(openai_output)} characters\")\n",
    "print(f\"   Token usage: {openai_usage}\")\n",
    "\n",
    "print(f\"\\n3. LLAMA 3.3 70B OUTPUT LENGTH: {len(llama_output)} characters\") \n",
    "print(f\"   Token usage: {llama_usage}\")\n",
    "\n",
    "print(f\"\\n4. ANALYSIS AND IMPROVED PROMPT LENGTH: {len(comparison_output)} characters\")\n",
    "print(f\"   Token usage: {comparison_usage}\")\n",
    "\n",
    "print(f\"\\n5. IMPROVED LLAMA OUTPUT LENGTH: {len(improved_llama_output)} characters\")\n",
    "print(f\"   Token usage: {improved_llama_usage}\")\n",
    "\n",
    "print(\"\\n6. COMPARISON:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Original Llama vs Improved Llama:\")\n",
    "print(f\"  Original: {len(llama_output)} chars, {llama_usage.total_tokens} tokens\")\n",
    "print(f\"  Improved: {len(improved_llama_output)} chars, {improved_llama_usage.total_tokens} tokens\")\n",
    "\n",
    "print(\"\\nTest completed! Check the outputs above to evaluate the effectiveness of the prompt optimization.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
